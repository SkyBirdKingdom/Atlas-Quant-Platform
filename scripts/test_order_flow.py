# scripts/test_order_flow.py
import sys
import os
from datetime import datetime, timedelta, timezone
import logging

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.database import SessionLocal
from backend.services.order_flow import OrderFlowFetcher, OrderFlowProcessor, OrderFlowService
from backend.core.logger import setup_logging

setup_logging()
logger = logging.getLogger("TestScript")

def main():
    logger.info("ðŸš€ å¼€å§‹è®¢å•æµæ•°æ®é›†æˆæµ‹è¯• (æµå¼ç‰ˆ)...")
    
    # init_db() 
    db = SessionLocal()
    
    try:
        fetcher = OrderFlowFetcher()
        processor = OrderFlowProcessor()
        storage = OrderFlowService(db)
        
        area = "SE3"
        # æ•…æ„è®¾ç½®ä¸€ä¸ªè¾ƒé•¿çš„æ—¶é—´æ®µæ¥æµ‹è¯•åˆ‡ç‰‡ (ä¾‹å¦‚è¿‡åŽ»5å°æ—¶ï¼Œè§¦å‘åˆ‡ç‰‡)
        end_time = datetime.now(timezone.utc)
        start_time = datetime(2025, 12, 23, 12, 0, 0, tzinfo=timezone.utc)
        
        logger.info(f"æµ‹è¯•èŒƒå›´: {area} | {start_time.isoformat()} -> {end_time.isoformat()}")
        
        total_ticks = 0
        
        # ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨ for å¾ªçŽ¯æ¶ˆè´¹ç”Ÿæˆå™¨
        # æ¯æ¬¡å¾ªçŽ¯å¤„ç†ä¸€ä¸ª 4å°æ—¶åˆ‡ç‰‡çš„æ•°æ®
        for chunk_idx, raw_data in enumerate(fetcher.fetch_recent_orders(area, start_time, end_time)):
            
            # 1. ç«‹å³å¤„ç†
            ticks = processor.process_recent_orders_response(area, raw_data)
            logger.info(f"ðŸ“¦ ç‰‡æ®µ {chunk_idx+1}: è§£æžå‡º {len(ticks)} æ¡æ•°æ®")
            
            if ticks:
                # 2. ç«‹å³å…¥åº“ (å¤„ç†å®Œå³é‡Šæ”¾å†…å­˜)
                storage.save_ticks(ticks)
                total_ticks += len(ticks)
                
                # æ‰“å°é¢„è§ˆ
                if chunk_idx == 0:
                    logger.info("--- æ•°æ®é¢„è§ˆ (First Chunk Top 3) ---")
                    for t in ticks[:3]:
                        logger.info(f"[{t.type}] {t.timestamp} | P:{t.price} | V:{t.volume} | {t.aggressor_side}")

        logger.info(f"ðŸ’¾ å…¨éƒ¨å®Œæˆï¼å…±å…¥åº“ {total_ticks} æ¡ Tick æ•°æ®")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
    finally:
        db.close()

def export_order_flow_ticks_to_csv(area: str, output_file: str):
    """
    è¾…åŠ©å‡½æ•°ï¼šå°†æŒ‡å®šåŒºåŸŸçš„ Order Flow Tick æ•°æ®å¯¼å‡ºä¸º CSV æ–‡ä»¶ï¼Œä¾¿äºŽç¦»çº¿åˆ†æž
    """
    import pandas as pd
    db = SessionLocal()
    try:
        start = datetime(2025, 12, 23, 23, 0, 0, tzinfo=timezone.utc)
        end = start + timedelta(days=1)
        from backend.models import OrderFlowTick
        query = db.query(OrderFlowTick).filter(OrderFlowTick.delivery_area == area,
                                                OrderFlowTick.delivery_start >= start,
                                                OrderFlowTick.delivery_start < end)
        df = pd.read_sql(query.statement, db.bind)
        df.to_csv(output_file, index=False)
        logger.info(f"âœ… å·²å¯¼å‡º {len(df)} æ¡ Order Flow Tick åˆ°æ–‡ä»¶: {output_file}")
    finally:
        db.close()

if __name__ == "__main__":
    export_order_flow_ticks_to_csv("SE3", "order_flow_ticks_20251224.csv")
    # main()