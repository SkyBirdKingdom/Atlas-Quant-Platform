from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from sqlalchemy.orm import Session
from .database import SessionLocal
from .services import fetcher, kline_generator, live_runner
from .services.live_trader import LiveTrader
import logging
from datetime import datetime, timedelta, timezone
from .models import MarketCandle
from .services.order_flow.manager import OrderFlowManager

logger = logging.getLogger("JobScheduler")

# åˆ›å»ºä¸€ä¸ªå…¨å±€å®ä¾‹ (ä¿æŒçŠ¶æ€)
# é»˜è®¤å¯åŠ¨ä¸º PAPER (æ¨¡æ‹Ÿç›˜) æ¨¡å¼
trader_instance = LiveTrader(area="SE3", mode="PAPER")

# åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
scheduler = BackgroundScheduler()

def job_function():
    """
    åŒ…è£…å™¨ï¼šåˆ›å»º DB ä¼šè¯ -> æ‰§è¡ŒåŒæ­¥ -> å…³é—­ä¼šè¯
    """
    db = SessionLocal()
    try:
        fetcher.sync_all_areas(db)
    except Exception as e:
        logger.error(f"Job Execution Error: {e}")
    finally:
        db.close()

def get_last_kline_time(db, area):
    """
    æŸ¥è¯¢æ•°æ®åº“ä¸­è¯¥åŒºåŸŸæœ€æ–°çš„ K çº¿æ—¶é—´æˆ³
    """
    # å‡è®¾ä½ çš„ KLine æ¨¡å‹å« KLineModelï¼Œæ—¶é—´å­—æ®µå« timestamp
    last_record = db.query(MarketCandle.timestamp)\
                    .filter(MarketCandle.area == area)\
                    .order_by(MarketCandle.timestamp.desc())\
                    .first()
    
    if last_record:
        ts = last_record[0]
        # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœè¯»å‡ºæ¥çš„æ—¶é—´æ²¡æœ‰æ—¶åŒºä¿¡æ¯ (Naive)ï¼Œç»™å®ƒå¼ºè¡ŒåŠ ä¸Š UTC
        if ts.tzinfo is None:
            ts = ts.replace(tzinfo=timezone.utc)
        return ts
    else:
        # å¦‚æœæ•°æ®åº“æ˜¯ç©ºçš„ï¼Œç»™ä¸€ä¸ªé»˜è®¤çš„èµ·å§‹æ—¶é—´ï¼Œ2024-12-31 23:59:00 UTC
        return datetime(2024, 12, 31, 23, 59, 0, tzinfo=timezone.utc)

def kline_job_function():
    """
    æ”¹è¿›åçš„å®šæ—¶ä»»åŠ¡ï¼šè‡ªåŠ¨æ–­ç‚¹ç»­ä¼ ï¼Œä»ä¸Šæ¬¡ç»“æŸçš„åœ°æ–¹å¼€å§‹ç”Ÿæˆï¼Œç›´åˆ°è¿½ä¸Šç°åœ¨
    """
    db = SessionLocal()
    try:
        # è®¾å®šç»“æŸæ—¶é—´ä¸ºå½“å‰æ—¶é—´ï¼ˆç¨å¾®ç•™ç‚¹ä½™é‡ï¼Œæ¯”å¦‚å»¶è¿Ÿ1åˆ†é’Ÿï¼Œç¡®ä¿Tradeæ•°æ®å·²è½åº“ï¼‰
        target_end_dt = datetime.now(timezone.utc) - timedelta(minutes=1)
        
        for area in ["SE1", "SE2", "SE3", "SE4"]:
            # 1. æ™ºèƒ½è·å–å¼€å§‹æ—¶é—´ï¼šä»æ•°æ®åº“é‡Œæ‰¾ä¸Šæ¬¡æœ€åç”Ÿæˆçš„æ—¶é—´
            last_kline_time = get_last_kline_time(db, area)
            
            # ä¸‹ä¸€æ ¹ K çº¿çš„å¼€å§‹æ—¶é—´åº”è¯¥æ˜¯ä¸Šä¸€æ ¹çš„æ—¶é—´ + 1åˆ†é’Ÿ (å‡è®¾æ˜¯1åˆ†é’ŸKçº¿)
            start_dt = last_kline_time + timedelta(minutes=1)
            
            # å¦‚æœå¼€å§‹æ—¶é—´å·²ç»æ¯”ç°åœ¨è¿˜æ™šï¼Œè¯´æ˜ä¸éœ€è¦ç”Ÿæˆï¼Œè·³è¿‡
            if start_dt >= target_end_dt:
                continue

            # 2. æ‰“å°æ—¥å¿—ï¼Œæ–¹ä¾¿è§‚å¯Ÿè¿½èµ¶è¿›åº¦
            logger.info(f"[{area}] æ£€æµ‹åˆ°æ•°æ®æ–­ç‚¹ï¼Œå¼€å§‹è¿½èµ¶æ•°æ®: {start_dt} -> {target_end_dt}")
            
            # 3. åˆ†æ‰¹æ¬¡å¤„ç† (éå¸¸é‡è¦ï¼)
            # å¦‚æœä¸­é—´æ–­äº†å‡ å¤©ï¼Œç›´æ¥è·‘å‡ å¤©çš„æ•°æ®å¯èƒ½ä¼šå†…å­˜æº¢å‡ºæˆ–æ•°æ®åº“è¶…æ—¶
            # å»ºè®®åˆ‡åˆ†æˆå°å—ï¼Œæ¯”å¦‚æ¯æ¬¡æœ€å¤šè¡¥ 6 å°æ—¶çš„æ•°æ®
            chunk_size = timedelta(hours=6)
            current_pointer = start_dt
            
            while current_pointer < target_end_dt:
                # ç¡®å®šå½“å‰æ‰¹æ¬¡çš„ç»“æŸæ—¶é—´
                batch_end = min(current_pointer + chunk_size, target_end_dt)
                
                start_str = current_pointer.strftime('%Y-%m-%dT%H:%M:%SZ')
                end_str = batch_end.strftime('%Y-%m-%dT%H:%M:%SZ')
                
                # è°ƒç”¨ç”Ÿæˆé€»è¾‘
                kline_generator.generate_1min_candles(db, area, start_str, end_str)
                
                # ç§»åŠ¨æŒ‡é’ˆ
                current_pointer = batch_end
                db.commit() # æ¯ä¸€æ‰¹æ¬¡æäº¤ä¸€æ¬¡ï¼Œé˜²æ­¢é•¿äº‹åŠ¡
            
            # --- é˜¶æ®µäºŒï¼šå®ç›˜ä¿¡å·åˆ†æ (æ–°å¢) ---
            try:
                # åªæœ‰å½“æ•°æ®æ˜¯â€œæ–°é²œâ€çš„ï¼ˆæ¯”å¦‚æœ€è¿‘1å°æ—¶å†…æœ‰æ•°æ®ï¼‰ï¼Œæ‰è·‘åˆ†æ
                # é˜²æ­¢è¡¥å½•ä¸€å¹´å‰æ•°æ®æ—¶ç–¯ç‹‚æŠ¥è­¦
                latest_check = get_last_kline_time(db, area)
                if latest_check > target_end_dt - timedelta(hours=2):
                    result = live_runner.run_live_analysis(db, area)
                    
                    if result and result['signal'] != "NEUTRAL":
                        logger.info(f"ğŸš€ğŸš€ğŸš€ [{area}] è§¦å‘é‡ç£…ä¿¡å·: {result['signal']} | RSI: {result['rsi']:.2f}")
                        # TODO: è¿™é‡Œæ˜¯æœªæ¥æ¥ Telegram æŠ¥è­¦çš„åœ°æ–¹
            except Exception as e:
                logger.error(f"[{area}] ä¿¡å·åˆ†æå¤±è´¥: {e}")

    except Exception as e:
        logger.error(f"Kline Gen Job Error: {e}")
        db.rollback()
    finally:
        db.close()

def run_live_trading_job():
    """
    å®ç›˜/æ¨¡æ‹Ÿç›˜ è°ƒåº¦ä»»åŠ¡
    å»ºè®®æ¯ 15 åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    """
    logger.info("â° è§¦å‘å®ç›˜å¾ªç¯ä»»åŠ¡...")
    trader_instance.run_tick()

def order_flow_sync_job():
    """
    ã€æ–°å¢ã€‘è®¢å•æµè‡ªåŠ¨åŒæ­¥ä»»åŠ¡
    """
    db = SessionLocal()
    try:
        manager = OrderFlowManager(db)
        manager.sync_all()
    except Exception as e:
        logger.error(f"Order Flow Sync Job Error: {e}")
    finally:
        db.close()

def start_scheduler():
    if not scheduler.running:
        # æ·»åŠ ä»»åŠ¡ï¼šæ¯ 1 å°æ—¶æ‰§è¡Œä¸€æ¬¡
        # 'replace' è¡¨ç¤ºå¦‚æœä»»åŠ¡å·²å­˜åœ¨ï¼Œè¦†ç›–å®ƒ
        scheduler.add_job(
            job_function,
            trigger=IntervalTrigger(hours=1), 
            id="auto_sync_nordpool",
            name="NordPool Auto Sync",
            replace_existing=True,
            misfire_grace_time=3600,
            coalesce=True
        )

        scheduler.add_job(
            kline_job_function, 
            trigger=IntervalTrigger(minutes=15), 
            id="auto_kline_gen",
            name="Realtime Kline Gen",
            replace_existing=True,
            misfire_grace_time=3600,
            coalesce=True
        )

        scheduler.add_job(
            run_live_trading_job, 
            trigger=IntervalTrigger(minutes=5), 
            id="live_trading_job",
            replace_existing=True,
            max_instances=1, # å¼ºåˆ¶å•å®ä¾‹
            misfire_grace_time=300
        )

        scheduler.add_job(
            order_flow_sync_job,
            id="startup_order_flow_sync", # ID å¿…é¡»å’Œä¸Šé¢çš„ä¸ä¸€æ ·
            name="Startup Order Flow Sync",
            replace_existing=True,
            misfire_grace_time=3600,
            coalesce=True
        )

        # ä¸åŠ  trigger å‚æ•°ï¼Œé»˜è®¤å°±æ˜¯ "DateTrigger(run_date=now)"ï¼Œå³ç«‹å³æ‰§è¡Œä¸€æ¬¡
        scheduler.add_job(
            job_function, 
            id="startup_sync_immediate",
            name="Startup Sync",
            replace_existing=True,
            misfire_grace_time=3600
        )
        scheduler.add_job(
            kline_job_function,
            id="startup_kline_immediate",
            name="Startup Kline Immediate",
            replace_existing=True,
            misfire_grace_time=3600
        )

        scheduler.add_job(
            order_flow_sync_job,
            trigger=IntervalTrigger(hours=1), # æˆ– minutes=30
            id="auto_order_flow_sync",
            name="Order Flow Auto Sync",
            replace_existing=True,
            misfire_grace_time=3600
        )
        
        # å¯åŠ¨è°ƒåº¦å™¨
        scheduler.start()
        logger.info("âœ… åå°è°ƒåº¦å™¨å·²å¯åŠ¨ï¼šæ¯ 1 å°æ—¶è‡ªåŠ¨åŒæ­¥æ•°æ®ã€‚")
        
        # --- å¯åŠ¨æ—¶ç«‹å³è¿è¡Œä¸€æ¬¡ (å¯é€‰) ---
        # è¿™æ ·ä¸ç”¨ç­‰ 1 å°æ—¶ï¼Œç³»ç»Ÿé‡å¯å°±é©¬ä¸Šæ£€æŸ¥æ›´æ–°
        # scheduler.add_job(job_function, id="startup_sync") 

def stop_scheduler():
    if scheduler.running:
        scheduler.shutdown(wait=False)
        logger.info("ğŸ›‘ åå°è°ƒåº¦å™¨å·²å…³é—­")