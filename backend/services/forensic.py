import os
import pandas as pd
import numpy as np
from sqlalchemy.orm import Session
from sqlalchemy import func, and_
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional
from ..models import Trade, OrderFlowTick, OrderContract

class MarketForensics:
    """
    å¸‚åœºå¾®è§‚ç»“æ„å–è¯åˆ†æå™¨ (æ··åˆå­˜å‚¨ç‰ˆ)
    æ”¯æŒè‡ªåŠ¨è·¯ç”±ï¼šçƒ­æ•°æ®(DB) / å†·æ•°æ®(Parquet)
    """

    def __init__(self, db: Session):
        self.db = db
        self.base_data_dir = "data/order_flow" # ä¸ storage.py ä¿æŒä¸€è‡´

    def detect_price_anomalies(self, area: str, start_date: str, end_date: str, threshold_pct: float = 0.05, target_contract_id: Optional[str] = None):
        """
        ã€ç¬¬ä¸€æ­¥ã€‘å®è§‚æ‰«æï¼šå¯»æ‰¾ä»·æ ¼å¼‚å¸¸æ³¢åŠ¨çš„æ—¶é—´çª—å£
        (é€»è¾‘ä¿æŒä¸å˜ï¼Œå› ä¸º Trade æ•°æ®é€šå¸¸å…¨é‡åœ¨ DB ä¸­ï¼Œæˆ–è€… Trade æ•°æ®é‡å°ä¸€ç›´å­˜ DB)
        """
        query = self.db.query(Trade.trade_time, Trade.price, Trade.contract_id)\
            .filter(
                Trade.delivery_area == area,
                Trade.trade_time >= start_date,
                Trade.trade_time <= end_date
            )
        
        if target_contract_id:
            query = query.filter(Trade.contract_id == target_contract_id)
            
        trades = query.order_by(Trade.trade_time).all()
            
        if not trades:
            return []

        df = pd.DataFrame([{
            'time': t.trade_time, 
            'price': t.price, 
            'contract': t.contract_id
        } for t in trades])
        
        if df.empty:
            return []
            
        df.set_index('time', inplace=True)
        
        # æŒ‰ 5åˆ†é’Ÿ åˆ†ç»„
        ohlc = df.groupby([pd.Grouper(freq='5T'), 'contract'])['price'].agg(['first', 'max', 'min', 'last']).reset_index()
        
        anomalies = []
        for _, row in ohlc.iterrows():
            open_px = row['first']
            if open_px <= 0: continue
            
            pump_pct = (row['max'] - open_px) / open_px
            dump_pct = (row['min'] - open_px) / open_px
            
            anomaly_type = None
            change_pct = 0
            
            if pump_pct > threshold_pct:
                anomaly_type = "Pump"
                change_pct = pump_pct
            elif dump_pct < -threshold_pct:
                anomaly_type = "Dump"
                change_pct = dump_pct
            
            if anomaly_type:
                anomalies.append({
                    "contract_id": row['contract'],
                    "start_time": row['time'],
                    "end_time": row['time'] + timedelta(minutes=5),
                    "open": open_px,
                    "high": row['max'] if anomaly_type == "Pump" else row['min'],
                    "change_pct": round(change_pct * 100, 2),
                    "type": anomaly_type
                })
                
        return sorted(anomalies, key=lambda x: abs(x['change_pct']), reverse=True)

    def _load_ticks(self, contract_id: str, start_time: datetime, end_time: datetime) -> List[Dict]:
        """
        ã€æ ¸å¿ƒé€»è¾‘ã€‘æ™ºèƒ½åŠ è½½æ•°æ® (Parquet ä¼˜å…ˆ -> DB å…œåº•)
        """
        ticks_data = []
        
        # 1. è·å–åˆçº¦å…ƒæ•°æ®ä»¥ç¡®å®šæ–‡ä»¶è·¯å¾„
        contract = self.db.query(OrderContract).filter(OrderContract.contract_id == contract_id).first()
        
        if contract and contract.delivery_date_utc:
            area = contract.delivery_area
            date_str = contract.delivery_date_utc.strftime('%Y-%m-%d')
            file_path = os.path.join(self.base_data_dir, area, date_str, f"{contract_id}.parquet")
            
            # --- å°è¯•åŠ è½½å†·æ•°æ® (Parquet) ---
            if os.path.exists(file_path):
                try:
                    df = pd.read_parquet(file_path)
                    
                    # ç¡®ä¿æ—¶é—´åˆ—ä¸º datetime ä¸”å¸¦æ—¶åŒº
                    if 'updated_time' in df.columns:
                        df['updated_time'] = pd.to_datetime(df['updated_time'])
                        # å¦‚æœ parquet é‡Œå­˜çš„æ˜¯ naive æ—¶é—´ï¼Œå‡å®šä¸º UTC
                        if df['updated_time'].dt.tz is None:
                            df['updated_time'] = df['updated_time'].dt.tz_localize('UTC')
                        
                        # ç¡®ä¿ start_time/end_time å¸¦æ—¶åŒº
                        if start_time.tzinfo is None: start_time = start_time.replace(tzinfo=timezone.utc)
                        if end_time.tzinfo is None: end_time = end_time.replace(tzinfo=timezone.utc)

                        # è¿‡æ»¤æ—¶é—´æ®µ
                        mask = (df['updated_time'] >= start_time) & (df['updated_time'] <= end_time)
                        filtered_df = df[mask]
                        
                        # è½¬ä¸ºå­—å…¸åˆ—è¡¨
                        ticks_data = filtered_df.to_dict('records')
                        return ticks_data
                        
                except Exception as e:
                    print(f"[Forensic] è¯»å– Parquet å¤±è´¥ï¼Œå°è¯•æŸ¥åº“: {e}")

        # --- é™çº§åŠ è½½çƒ­æ•°æ® (DB) ---
        # ä¿®æ­£å­—æ®µå timestamp -> updated_time
        db_ticks = self.db.query(OrderFlowTick).filter(
            OrderFlowTick.contract_id == contract_id,
            OrderFlowTick.updated_time >= start_time,
            OrderFlowTick.updated_time <= end_time
        ).order_by(OrderFlowTick.updated_time).all()
        
        # å°† ORM å¯¹è±¡è½¬ä¸ºå­—å…¸ï¼Œä¸ Parquet æ ¼å¼ç»Ÿä¸€
        for t in db_ticks:
            ticks_data.append({
                "volume": t.volume,
                "price": t.price,
                "side": t.side,
                "is_deleted": t.is_deleted,
                "updated_time": t.updated_time,
                "priority_time": t.priority_time
            })
            
        return ticks_data

    def analyze_microstructure(self, contract_id: str, start_time: datetime, end_time: datetime):
        """
        ã€ç¬¬äºŒæ­¥ã€‘å¾®è§‚åˆ†æ
        """
        # ä½¿ç”¨é€šç”¨åŠ è½½å™¨è·å–æ•°æ®
        ticks = self._load_ticks(contract_id, start_time, end_time)
        
        if not ticks:
            return {
                "total_volume": 0,
                "aggressive_buy_ratio": 0,
                "spoofing_ratio_buy": 0,
                "spoofing_ratio_sell": 0,
                "large_orders": [],
                "conclusion": "è¯¥æ—¶æ®µæ— è®¢å•æµæ•°æ®(DB/Fileå‡æœªæ‰¾åˆ°)"
            }

        metrics = {
            "total_volume": 0,
            "limit_buy_added": 0,      
            "limit_buy_canceled": 0,   
            "limit_sell_added": 0,
            "limit_sell_canceled": 0,
            "large_orders": []         
        }
        
        large_order_threshold = 20 
        
        for t in ticks:
            # å…¼å®¹å¤„ç†ï¼šParquetè¯»å‡ºæ¥æ˜¯å­—å…¸ï¼ŒDBè¯»å‡ºæ¥è½¬æˆäº†å­—å…¸
            vol = t.get('volume', 0)
            price = t.get('price', 0)
            side = t.get('side', 'UNKNOWN')
            is_deleted = t.get('is_deleted', False)
            # å¤„ç†æ—¶é—´æ ¼å¼ (å¯èƒ½æ˜¯ Timestamp å¯¹è±¡æˆ– datetime)
            ts = t.get('updated_time')
            time_str = ts.strftime('%H:%M:%S.%f') if hasattr(ts, 'strftime') else str(ts)

            # 3. æ’¤å•åˆ†æ (Deleted)
            if is_deleted:
                if side == 'BUY':
                    metrics["limit_buy_canceled"] += vol
                else:
                    metrics["limit_sell_canceled"] += vol
                    
                if vol >= large_order_threshold:
                    metrics["large_orders"].append({
                        "time": time_str,
                        "action": "CANCELED",
                        "side": side,
                        "price": price,
                        "volume": vol
                    })
            
            # 2. æŒ‚å•/ä¿®æ”¹åˆ†æ (éåˆ é™¤)
            else:
                if side == 'BUY':
                    metrics["limit_buy_added"] += vol
                else:
                    metrics["limit_sell_added"] += vol
                
                if vol >= large_order_threshold:
                    metrics["large_orders"].append({
                        "time": time_str,
                        "action": "PLACED",
                        "side": side,
                        "price": price,
                        "volume": vol
                    })

        # --- è®¡ç®—æŒ‡æ ‡ ---
        spoof_buy = (metrics["limit_buy_canceled"] / metrics["limit_buy_added"]) if metrics["limit_buy_added"] > 0 else 0
        spoof_sell = (metrics["limit_sell_canceled"] / metrics["limit_sell_added"]) if metrics["limit_sell_added"] > 0 else 0
        
        metrics["spoofing_ratio_buy"] = round(spoof_buy * 100, 2)
        metrics["spoofing_ratio_sell"] = round(spoof_sell * 100, 2)
        metrics["aggressive_buy_ratio"] = 0 # éœ€ç»“åˆ Trade è¡¨è®¡ç®—ï¼Œæš‚ç½® 0
        
        # ç»“è®º
        conclusion = []
        if spoof_buy > 0.8 and metrics["limit_buy_added"] > 50:
            conclusion.append("âš ï¸ ä¹°æ–¹ä¸¥é‡è¯±å¤š (Spoofing Buy): æŒ‚å¤šæ’¤å¤šã€‚")
        if spoof_sell > 0.8 and metrics["limit_sell_added"] > 50:
            conclusion.append("âš ï¸ å–æ–¹ä¸¥é‡è¯±ç©º (Spoofing Sell): æŒ‚å¤šæ’¤å¤šã€‚")
        if any(o['action'] == 'CANCELED' for o in metrics['large_orders']):
             conclusion.append("ğŸš¨ æ£€æµ‹åˆ°å¤§é¢è®¢å•æ’¤å•ã€‚")
        if not conclusion:
            conclusion.append("âœ… è®¢å•æµç›¸å¯¹å¹³ç¨³ã€‚")

        metrics["conclusion"] = " ".join(conclusion)
        return metrics